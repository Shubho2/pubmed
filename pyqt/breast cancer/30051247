132. Ann Biomed Eng. 2018 Jul 26. doi: 10.1007/s10439-018-2095-6. [Epub ahead ofprint]Classification of Tumor Epithelium and Stroma by Exploiting Image FeaturesLearned by Deep Convolutional Neural Networks.Du Y(1), Zhang R(2), Zargari A(1), Thai TC(3), Gunderson CC(4), Moxley KM(4), LiuH(1), Zheng B(1), Qiu Y(5).Author information: (1)School of Electrical and Computer Engineering, University of Oklahoma, Norman,OK, 73019, USA.(2)Department of Pathology, University of Oklahoma Health Sciences Center,Oklahoma City, OK, 73104, USA.(3)Department of Radiology, University of Oklahoma Health Sciences Center,Oklahoma City, OK, 73104, USA.(4)Department of Obstetrics and Gynecology, University of Oklahoma HealthSciences Center, Oklahoma City, OK, 73104, USA.(5)School of Electrical and Computer Engineering, University of Oklahoma, Norman,OK, 73019, USA. qiuyuchen@ou.edu.The tumor-stroma ratio (TSR) reflected on hematoxylin and eosin (H&E)-stainedhistological images is a potential prognostic factor for survival. Automaticimage processing techniques that allow for high-throughput and precisediscrimination of tumor epithelium and stroma are required to elevate theprognostic significance of the TSR. As a variant of deep learning techniques,transfer learning leverages nature-images features learned by deep convolutional neural networks (CNNs) to relieve the requirement of deep CNNs for immense samplesize when handling biomedical classification problems. Herein we studieddifferent transfer learning strategies for accurately distinguishing epithelialand stromal regions of H&E-stained histological images acquired from eitherbreast or ovarian cancer tissue. We compared the performance of important deepCNNs as either a feature extractor or as an architecture for fine-tuning withtarget images. Moreover, we addressed the current contradictory issue aboutwhether the higher-level features would generalize worse than lower-level onesbecause they are more specific to the source-image domain. Under our experimentalsetting, the transfer learning approach achieved an accuracy of 90.2 (vs. 91.1for fine tuning) with GoogLeNet, suggesting the feasibility of using it inassisting pathology-based binary classification problems. Our results also showthat the superiority of the lower-level or the higher-level features over theother ones was determined by the architecture of deep CNNs.DOI: 10.1007/s10439-018-2095-6 PMID: 30051247 