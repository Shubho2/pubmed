106. J Digit Imaging. 2018 Aug 3. doi: 10.1007/s10278-018-0114-7. [Epub ahead ofprint]Fully Automated Convolutional Neural Network Method for Quantification of Breast MRI Fibroglandular Tissue and Background Parenchymal Enhancement.Ha R(1), Chang P(2), Mema E(2), Mutasa S(2), Karcich J(2), Wynn RT(2), Liu MZ(3),Jambawalikar S(3).Author information: (1)Department of Radiology, Columbia University Medical Center, 622 West 168thStreet, PB-1-301, New York, NY, 10032, USA. rh2616@columbia.edu.(2)Department of Radiology, Columbia University Medical Center, 622 West 168thStreet, PB-1-301, New York, NY, 10032, USA.(3)Department of Medical Physics, Columbia University Medical Center, 177 Ft.Washington Ave. Milstein Bldg Room 3-124B, New York, NY, 10032-3784, USA.The aim of this study is to develop a fully automated convolutional neuralnetwork (CNN) method for quantification of breast MRI fibroglandular tissue (FGT)and background parenchymal enhancement (BPE). An institutional reviewboard-approved retrospective study evaluated 1114 breast volumes in 137 patients using T1 precontrast, T1 postcontrast, and T1 subtraction images. First, usingour previously published method of quantification, we manually segmented andcalculated the amount of FGT and BPE to establish ground truth parameters. Then, a novel 3D CNN modified from the standard 2D U-Net architecture was developed andimplemented for voxel-wise prediction whole breast and FGT margins. In thecollapsing arm of the network, a series of 3D convolutional filters of size3 × 3 × 3 are applied for standard CNN hierarchical feature extraction. To reducefeature map dimensionality, a 3 × 3 × 3 convolutional filter with stride 2 in alldirections is applied; a total of 4 such operations are used. In the expandingarm of the network, a series of convolutional transpose filters of size 3 × 3 × 3are used to up-sample each intermediate layer. To synthesize features at multipleresolutions, connections are introduced between the collapsing and expanding armsof the network. L2 regularization was implemented to prevent over-fitting. Cases were separated into training (80%) and test sets (20%). Fivefold cross-validationwas performed. Software code was written in Python using the TensorFlow module ona Linux workstation with NVIDIA GTX Titan X GPU. In the test set, the fullyautomated CNN method for quantifying the amount of FGT yielded accuracy of 0.813 (cross-validation Dice score coefficient) and Pearson correlation of 0.975. Forquantifying the amount of BPE, the CNN method yielded accuracy of 0.829 andPearson correlation of 0.955. Our CNN network was able to quantify FGT and BPEwithin an average of 0.42 s per MRI case. A fully automated CNN method can beutilized to quantify MRI FGT and BPE. Larger dataset will likely improve ourmodel.DOI: 10.1007/s10278-018-0114-7 PMID: 30076489 